(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[574],{2663:function(e,r,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/evaluation",function(){return s(5563)}])},4440:function(e,r,s){"use strict";s.d(r,{Z:function(){return b}});var a=s(7462),t=s(3366),i=s(7294),n=s(512),o=s(3390),c=s(6523),l=s(9707),d=s(6682),u=s(5893);let h=["className","component"];var m=s(1983),x=s(4191),p=s(5038);let v=(0,s(1977).Z)("MuiBox",["root"]),f=(0,x.Z)();var b=function(e={}){let{themeId:r,defaultTheme:s,defaultClassName:m="MuiBox-root",generateClassName:x}=e,p=(0,o.default)("div",{shouldForwardProp:e=>"theme"!==e&&"sx"!==e&&"as"!==e})(c.Z);return i.forwardRef(function(e,i){let o=(0,d.Z)(s),c=(0,l.Z)(e),{className:v,component:f="div"}=c,b=(0,t.Z)(c,h);return(0,u.jsx)(p,(0,a.Z)({as:f,ref:i,className:(0,n.Z)(v,x?x(m):m),theme:r&&o[r]||o},b))})}({themeId:p.Z,defaultTheme:f,defaultClassName:v.root,generateClassName:m.Z.generate})},9979:function(e,r,s){"use strict";s.d(r,{Z:function(){return y}});var a=s(3366),t=s(7462),i=s(7294),n=s(512),o=s(5463),c=s(8510),l=s(2908),d=s(9628),u=s(5098),h=s(7172),m=s(5893);let x=["className","component","disableGutters","fixed","maxWidth","classes"],p=(0,h.Z)(),v=(0,u.Z)("div",{name:"MuiContainer",slot:"Root",overridesResolver:(e,r)=>{let{ownerState:s}=e;return[r.root,r[`maxWidth${(0,l.Z)(String(s.maxWidth))}`],s.fixed&&r.fixed,s.disableGutters&&r.disableGutters]}}),f=e=>(0,d.Z)({props:e,name:"MuiContainer",defaultTheme:p}),b=(e,r)=>{let{classes:s,fixed:a,disableGutters:t,maxWidth:i}=e,n={root:["root",i&&`maxWidth${(0,l.Z)(String(i))}`,a&&"fixed",t&&"disableGutters"]};return(0,c.Z)(n,e=>(0,o.ZP)(r,e),s)};var j=s(5228),Z=s(9262),g=s(9145),y=function(e={}){let{createStyledComponent:r=v,useThemeProps:s=f,componentName:o="MuiContainer"}=e,c=r(({theme:e,ownerState:r})=>(0,t.Z)({width:"100%",marginLeft:"auto",boxSizing:"border-box",marginRight:"auto",display:"block"},!r.disableGutters&&{paddingLeft:e.spacing(2),paddingRight:e.spacing(2),[e.breakpoints.up("sm")]:{paddingLeft:e.spacing(3),paddingRight:e.spacing(3)}}),({theme:e,ownerState:r})=>r.fixed&&Object.keys(e.breakpoints.values).reduce((r,s)=>{let a=e.breakpoints.values[s];return 0!==a&&(r[e.breakpoints.up(s)]={maxWidth:`${a}${e.breakpoints.unit}`}),r},{}),({theme:e,ownerState:r})=>(0,t.Z)({},"xs"===r.maxWidth&&{[e.breakpoints.up("xs")]:{maxWidth:Math.max(e.breakpoints.values.xs,444)}},r.maxWidth&&"xs"!==r.maxWidth&&{[e.breakpoints.up(r.maxWidth)]:{maxWidth:`${e.breakpoints.values[r.maxWidth]}${e.breakpoints.unit}`}}));return i.forwardRef(function(e,r){let i=s(e),{className:l,component:d="div",disableGutters:u=!1,fixed:h=!1,maxWidth:p="lg"}=i,v=(0,a.Z)(i,x),f=(0,t.Z)({},i,{component:d,disableGutters:u,fixed:h,maxWidth:p}),j=b(f,o);return(0,m.jsx)(c,(0,t.Z)({as:d,ownerState:f,className:(0,n.Z)(j.root,l),ref:r},v))})}({createStyledComponent:(0,Z.ZP)("div",{name:"MuiContainer",slot:"Root",overridesResolver:(e,r)=>{let{ownerState:s}=e;return[r.root,r["maxWidth".concat((0,j.Z)(String(s.maxWidth)))],s.fixed&&r.fixed,s.disableGutters&&r.disableGutters]}}),useThemeProps:e=>(0,g.Z)({props:e,name:"MuiContainer"})})},5563:function(e,r,s){"use strict";s.r(r);var a=s(5893),t=s(9979),i=s(4246),n=s(4440),o=s(1664),c=s.n(o);r.default=()=>(0,a.jsxs)(t.Z,{children:[(0,a.jsx)(i.Z,{variant:"h3",component:"h3",gutterBottom:!0,children:"Measuring the Competition Results"}),(0,a.jsxs)(n.Z,{mb:4,children:[(0,a.jsx)(i.Z,{variant:"h4",component:"h4",gutterBottom:!0,children:"Case Law Competition Results (Tasks 1 and 2)"}),(0,a.jsxs)(i.Z,{variant:"body1",children:["For ",(0,a.jsx)(c(),{href:"/tasks#task1",children:"Tasks 1 and 2"}),", the evaluation metrics will be precision, recall, and F-measure:"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"Precision"})," =",(0,a.jsxs)(n.Z,{component:"span",children:["(",(0,a.jsx)("i",{children:"the number of correctly retrieved cases(paragraphs) for all queries"}),")"]}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"the number of retrieved cases(paragraphs) for all queries"}),")"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"Recall"})," =",(0,a.jsxs)(n.Z,{component:"span",children:["(",(0,a.jsx)("i",{children:"the number of correctly retrieved cases(paragraphs) for all queries"}),")"]}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"the number of relevant cases(paragraphs) for all queries"}),")"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"F-measure"})," =",(0,a.jsxs)(n.Z,{component:"span",children:["(",(0,a.jsx)("i",{children:"2 x Precision x Recall"}),")"]}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"Precision + Recall"}),")"]}),(0,a.jsx)(i.Z,{variant:"body1",sx:{mt:2},children:"In the evaluation of Task 1 and Task 2, we simply use micro-average (evaluation measure is calculated using the results of all queries) rather than macro-average (evaluation measure is calculated for each query and then take average)."})]}),(0,a.jsxs)(n.Z,{mb:4,children:[(0,a.jsx)(i.Z,{variant:"h4",component:"h4",gutterBottom:!0,children:"Statute Law Competition Results (Tasks 3 and 4)"}),(0,a.jsxs)(i.Z,{variant:"body1",children:["For ",(0,a.jsx)(c(),{href:"/tasks#task3",children:"Task 3"}),", the evaluation metrics will be precision, recall, and F2-measure (since IR process is a pre-process to select candidate articles for providing candidates which will be used in the entailment process, we put emphasis on recall), and it is:"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"Precision"})," =",(0,a.jsx)(n.Z,{component:"span",children:(0,a.jsx)("i",{children:"average of (the number of correctly retrieved articles for each query)"})}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"the number of retrieved articles for each query"}),")"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"Recall"})," =",(0,a.jsx)(n.Z,{component:"span",children:(0,a.jsx)("i",{children:"average of (the number of correctly retrieved articles for each query)"})}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"the number of relevant articles for each query"}),")"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"F2-measure"})," =",(0,a.jsxs)(n.Z,{component:"span",children:["(",(0,a.jsx)("i",{children:"5 x Precision x Recall"}),")"]}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"4 x Precision + Recall"}),")"]}),(0,a.jsx)(i.Z,{variant:"body1",sx:{mt:2},children:"In addition to the above evaluation measures, ordinal information retrieval measures such as Mean Average Precision and R-precision can be used for discussing the characteristics of the submission results."}),(0,a.jsx)(i.Z,{variant:"body1",sx:{mt:2},children:"In COLIEE 2024, the method used to calculate the final evaluation score of all queries is macro-average (evaluation measure is calculated for each query and their average is used as the final evaluation measure) instead of micro-average (evaluation measure is calculated using results of all queries)."}),(0,a.jsxs)(i.Z,{variant:"body1",sx:{mt:2},children:["For ",(0,a.jsx)(c(),{href:"/tasks#task4",children:"Task 4"}),", the evaluation measure will be accuracy, with respect to whether the yes/no question was correctly confirmed:"]}),(0,a.jsxs)(i.Z,{variant:"body1",component:"div",sx:{mt:2},children:[(0,a.jsx)("b",{children:"Accuracy"})," =",(0,a.jsxs)(n.Z,{component:"span",children:["(",(0,a.jsx)("i",{children:"the number of queries which were correctly confirmed as true or false"}),")"]}),(0,a.jsx)("br",{}),"(",(0,a.jsx)("i",{children:"the number of all queries"}),")"]})]})]})}},function(e){e.O(0,[888,774,179],function(){return e(e.s=2663)}),_N_E=e.O()}]);